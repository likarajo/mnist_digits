{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "XktdyEG9VgG0",
        "outputId": "2d665824-dff5-4cc9-d4ec-be39e5019c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "################################################################################\n",
        "#\n",
        "# LOGISTICS\n",
        "#\n",
        "#    Rajarshi Chattopadhyay\n",
        "#    RXC170010\n",
        "#\n",
        "# DESCRIPTION\n",
        "#\n",
        "#    MNIST image classification with a CNN written and trained in Python\n",
        "#\n",
        "# INSTRUCTIONS\n",
        "#\n",
        "#    1. Go to Google Colaboratory: https://colab.research.google.com/notebooks/welcome.ipynb\n",
        "#    2. File - New Python 3 notebook\n",
        "#    3. Cut and paste this file into the cell (feel free to divide into multiple cells)\n",
        "#    4. Runtime - Run all\n",
        "#\n",
        "# NOTES\n",
        "#\n",
        "#    1. This does not use PyTorch, TensorFlow or any other xNN library\n",
        "#\n",
        "#    2. Summary cnn.py: Each layer represented as a class. Structure of each layer is displayed at the end.\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# IMPORT\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "#\n",
        "# you should not need any import beyond the below\n",
        "# PyTorch, TensorFlow, ... is not allowed\n",
        "#\n",
        "\n",
        "import os.path\n",
        "import urllib.request\n",
        "import gzip\n",
        "import math\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# PARAMETERS\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# data\n",
        "DATA_NUM_TRAIN = 60000\n",
        "DATA_NUM_TEST = 10000\n",
        "DATA_CHANNELS = 1\n",
        "DATA_ROWS = 28\n",
        "DATA_COLS = 28\n",
        "DATA_CLASSES = 10\n",
        "DATA_URL_TRAIN_DATA = 'http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz'\n",
        "DATA_URL_TRAIN_LABELS = 'http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz'\n",
        "DATA_URL_TEST_DATA = 'http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz'\n",
        "DATA_URL_TEST_LABELS = 'http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz'\n",
        "DATA_FILE_TRAIN_DATA = 'train_data.gz'\n",
        "DATA_FILE_TRAIN_LABELS = 'train_labels.gz'\n",
        "DATA_FILE_TEST_DATA = 'test_data.gz'\n",
        "DATA_FILE_TEST_LABELS = 'test_labels.gz'\n",
        "\n",
        "# display\n",
        "DISPLAY_ROWS = 8\n",
        "DISPLAY_COLS = 4\n",
        "DISPLAY_COL_IN = 10\n",
        "DISPLAY_ROW_IN = 25\n",
        "DISPLAY_NUM = DISPLAY_ROWS * DISPLAY_COLS\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# DATA\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# download\n",
        "if not os.path.exists(DATA_FILE_TRAIN_DATA):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_DATA, DATA_FILE_TRAIN_DATA)\n",
        "if not os.path.exists(DATA_FILE_TRAIN_LABELS):\n",
        "    urllib.request.urlretrieve(DATA_URL_TRAIN_LABELS, DATA_FILE_TRAIN_LABELS)\n",
        "if not os.path.exists(DATA_FILE_TEST_DATA):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_DATA, DATA_FILE_TEST_DATA)\n",
        "if not os.path.exists(DATA_FILE_TEST_LABELS):\n",
        "    urllib.request.urlretrieve(DATA_URL_TEST_LABELS, DATA_FILE_TEST_LABELS)\n",
        "\n",
        "# training data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_train_data = gzip.open(DATA_FILE_TRAIN_DATA, 'r')\n",
        "file_train_data.read(16)\n",
        "buffer_train_data = file_train_data.read(DATA_NUM_TRAIN * DATA_ROWS * DATA_COLS)\n",
        "train_data = np.frombuffer(buffer_train_data, dtype=np.uint8).astype(np.float32)\n",
        "train_data = train_data.reshape(DATA_NUM_TRAIN, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# training labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_train_labels = gzip.open(DATA_FILE_TRAIN_LABELS, 'r')\n",
        "file_train_labels.read(8)\n",
        "buffer_train_labels = file_train_labels.read(DATA_NUM_TRAIN)\n",
        "train_labels = np.frombuffer(buffer_train_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# testing data\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to NCHW\n",
        "file_test_data = gzip.open(DATA_FILE_TEST_DATA, 'r')\n",
        "file_test_data.read(16)\n",
        "buffer_test_data = file_test_data.read(DATA_NUM_TEST * DATA_ROWS * DATA_COLS)\n",
        "test_data = np.frombuffer(buffer_test_data, dtype=np.uint8).astype(np.float32)\n",
        "test_data = test_data.reshape(DATA_NUM_TEST, 1, DATA_ROWS, DATA_COLS)\n",
        "\n",
        "# testing labels\n",
        "# unzip the file, skip the header, read the rest into a buffer and format to a vector\n",
        "file_test_labels = gzip.open(DATA_FILE_TEST_LABELS, 'r')\n",
        "file_test_labels.read(8)\n",
        "buffer_test_labels = file_test_labels.read(DATA_NUM_TEST)\n",
        "test_labels = np.frombuffer(buffer_test_labels, dtype=np.uint8).astype(np.int32)\n",
        "\n",
        "# debug\n",
        "# print(train_data.shape)   # (60000, 1, 28, 28)\n",
        "# print(train_labels.shape) # (60000,)\n",
        "# print(test_data.shape)    # (10000, 1, 28, 28)\n",
        "# print(test_labels.shape)  # (10000,)\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# YOUR CODE GOES HERE\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# Functions\n",
        "\n",
        "def cast_dim(dim):\n",
        "    return (dim,) if type(dim) != tuple and type(dim) != list else list(dim)\n",
        "\n",
        "def cross_entropy_loss(x, x_true):\n",
        "    return -1 * np.log(x[x_true] + 1e-5)\n",
        "\n",
        "# Classes\n",
        "\n",
        "class Layer:\n",
        "    def __init__(self, input_dim):\n",
        "        self.input_dim = input_dim\n",
        "        self.input_size = input_dim\n",
        "        self.output_size = input_dim\n",
        "        self.param_size = 0\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.output = input\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        return derivative\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.input = self.output = None\n",
        "        return\n",
        "\n",
        "\n",
        "class WeightedLayer(Layer):\n",
        "    def __init__(self, input_dim, weight_dim):\n",
        "        self.weight_dim = weight_dim\n",
        "        super().__init__(input_dim)\n",
        "        self.weights = np.random.normal(0, 1, weight_dim)/100\n",
        "        self.update_weights = np.zeros(weight_dim)\n",
        "        self.input_size = input_dim\n",
        "        self.output_size = input_dim\n",
        "        self.param_size = weight_dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        return super().forward(input)\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        return super().backward(derivative)\n",
        "\n",
        "    def update(self, lr):\n",
        "        self.weights = self.weights - (lr * self.update_weights)\n",
        "        self.update_weights = np.zeros(self.weight_dim)\n",
        "        #self.input = self.output = None\n",
        "\n",
        "\n",
        "class Normalize(Layer):\n",
        "    def __init__(self, input_dim, norm_constant):\n",
        "        super().__init__(input_dim)\n",
        "        self.norm_constant = norm_constant\n",
        "        self.input_size = input_dim\n",
        "        self.output_size = input_dim\n",
        "        self.param_size = 0\n",
        "\n",
        "    def forward(self, input):\n",
        "        return super().forward(input / self.norm_constant)\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        return None\n",
        "\n",
        "\n",
        "class Vectorizer(Layer):\n",
        "    def __init__(self, input_dim):\n",
        "        super().__init__(input_dim)\n",
        "        self.output_dim = (1, np.product(input_dim))\n",
        "        self.input_size = input_dim\n",
        "        self.output_size = self.output_dim\n",
        "        self.param_size = 0\n",
        "\n",
        "    def forward(self, input):\n",
        "        return super().forward(np.reshape(input, self.output_dim))\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        return np.reshape(derivative, self.input_dim)\n",
        "\n",
        "\n",
        "class MatrixMult(WeightedLayer):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        input_dim = cast_dim(input_dim)\n",
        "        output_dim = cast_dim(output_dim)\n",
        "        self.h_dim = (input_dim[-1], output_dim[-1])\n",
        "        super().__init__(self, self.h_dim)\n",
        "        self.input_size = (input_dim[0], input_dim[1])\n",
        "        self.output_size = (output_dim[0], output_dim[1])\n",
        "        self.param_size = 0\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return super().forward(np.matmul(input, self.weights))\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        self.update_weights += np.matmul(np.transpose(self.input), derivative)\n",
        "        return np.matmul(derivative, np.transpose(self.weights))\n",
        "\n",
        "\n",
        "class Addition(WeightedLayer):\n",
        "    def __init__(self, input_dim):\n",
        "        input_dim = cast_dim(input_dim)\n",
        "        self.h_dim = input_dim\n",
        "        super().__init__(self, self.h_dim)\n",
        "        self.input_size = (input_dim[0], input_dim[1])\n",
        "        self.output_size = (input_dim[0], input_dim[1])\n",
        "        self.param_size = 0\n",
        "\n",
        "    def forward(self, input):\n",
        "        return super().forward(self.weights + input)\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        self.update_weights += derivative\n",
        "        return derivative\n",
        "\n",
        "\n",
        "class ReLUActi(Layer):\n",
        "    def __init__(self):\n",
        "        self.input_size = 0\n",
        "        self.output_size = 0\n",
        "        self.param_size = 0\n",
        "        pass\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        self.input_dim = input.shape\n",
        "        return super().forward(np.maximum(input, 0))\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        return derivative * (self.input > 0)\n",
        "\n",
        "\n",
        "class SoftMaxActi(Layer):\n",
        "    def __init__(self):\n",
        "        self.input_size = 0\n",
        "        self.output_size = 0\n",
        "        self.param_size = 0\n",
        "        pass\n",
        "\n",
        "    def softmax(self, x):\n",
        "        return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input_dim = input.shape\n",
        "        return super().forward(self.softmax(input))\n",
        "\n",
        "    def backward(self, x_true):\n",
        "        derivative = self.output\n",
        "        derivative[0][x_true] -= 1\n",
        "        return derivative\n",
        "\n",
        "class Conv2D(WeightedLayer):\n",
        "    def __init__(self, input_dim, output_dim, filter_dim, stride):\n",
        "        super().__init__(input_dim, filter_dim)\n",
        "        self.filter_dim = filter_dim\n",
        "        self.stride = stride\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_dim\n",
        "        self.output_size = output_dim\n",
        "        self.param_size = filter_dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = np.pad(input, [[0, 0], [1, 1], [1, 1]])\n",
        "        output = np.zeros(self.output_dim)\n",
        "        channels = self.filter_dim[0]\n",
        "        filter_x = self.filter_dim[1]\n",
        "        filter_y = self.filter_dim[2]\n",
        "        for i in range(len(self.input) * channels):\n",
        "            for j in range(self.output_dim[1] - filter_y):\n",
        "                for k in range(self.output_dim[2] - filter_x):\n",
        "                    j_stride = j * self.stride\n",
        "                    k_stride = k * self.stride\n",
        "                    output[i][j][k] += np.sum(self.input[:,j_stride:j_stride + filter_y, k_stride:k_stride + filter_x] * self.weights[i // len(self.input)])\n",
        "        return output\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        channels = self.filter_dim[0]\n",
        "        filter_x = self.filter_dim[1]\n",
        "        filter_y = self.filter_dim[2]\n",
        "        new_derivative = np.zeros(self.input_dim)\n",
        "        for i in range(len(self.input) * channels):\n",
        "            for j in range(self.output_dim[1] - filter_y):\n",
        "                for k in range(self.output_dim[2] - filter_x):\n",
        "                    j_stride = j * self.stride\n",
        "                    k_stride = k * self.stride\n",
        "                    error = derivative[i][j][k] * self.input[i // channels][j_stride:j_stride + filter_y, k_stride:k_stride + filter_x]\n",
        "                    self.update_weights[i // len(self.input)] += error\n",
        "                    new_derivative[:,j_stride:j_stride + filter_y, k_stride:k_stride + filter_x] += error\n",
        "        return new_derivative\n",
        "\n",
        "class MaxPool(Layer):\n",
        "    def __init__(self, input_dim, output_dim, filter_dim, stride):\n",
        "        super().__init__(input_dim)\n",
        "        self.filter_dim = filter_dim\n",
        "        self.stride = stride\n",
        "        self.output_dim = output_dim\n",
        "        self.input_size = input_dim\n",
        "        self.output_size = output_dim\n",
        "        self.param_size = filter_dim\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = np.pad(input, [[0, 0], [1, 1], [1, 1]])\n",
        "        output = np.zeros(self.output_dim)\n",
        "        channels = self.filter_dim[0]\n",
        "        filter_x = self.filter_dim[1]\n",
        "        filter_y = self.filter_dim[2]\n",
        "        for i in range(len(self.input) * channels):\n",
        "                for j in range(self.output_dim[1]):\n",
        "                    for k in range(self.output_dim[2]):\n",
        "                        j_stride = j * self.stride\n",
        "                        k_stride = k * self.stride\n",
        "                        output[i][j][k] = np.max(input[i // channels][j_stride:j_stride + filter_y, k_stride:k_stride + filter_x])\n",
        "        return output\n",
        "\n",
        "    def backward(self, derivative):\n",
        "        channels = self.filter_dim[0]\n",
        "        filter_x = self.filter_dim[1]\n",
        "        filter_y = self.filter_dim[2]\n",
        "        new_derivative = np.zeros(self.input_dim)\n",
        "        for i in range(len(self.input) * channels):\n",
        "            for j in range(self.output_dim[1] - filter_y):\n",
        "                for k in range(self.output_dim[2] - filter_x):\n",
        "                    j_stride = j * self.stride\n",
        "                    k_stride = k * self.stride\n",
        "                    region = self.input[i // channels][j_stride:j_stride + filter_y, k_stride:k_stride + filter_x]\n",
        "                    error = derivative[i][j][k] * (region == np.max(region))\n",
        "                    new_derivative[:,j_stride:j_stride + filter_y, k_stride:k_stride + filter_x] = error\n",
        "        return new_derivative\n",
        "\n",
        "\n",
        "class Model:\n",
        "    def __init__(self):\n",
        "        self.layers = [\n",
        "            Normalize((1, 28, 28), 255.0),\n",
        "            Conv2D((1, 28, 28), (16, 28, 28), (16, 1, 3, 3), 1),\n",
        "            Addition((16, 28, 28)),\n",
        "            ReLUActi(),\n",
        "            MaxPool((16, 28, 28), (16, 14, 14), (1, 3, 3), 2),\n",
        "            Conv2D((16, 14, 14), (32, 14, 14), (32, 16, 3, 3), 1),\n",
        "            Addition((32, 14, 14)),\n",
        "            ReLUActi(),\n",
        "            MaxPool((32, 14, 14), (32, 7, 7), (1, 3, 3), 2),\n",
        "            Conv2D((32, 7, 7), (64, 7, 7), (64, 32, 3, 3), 1),\n",
        "            Addition((64, 7, 7)),\n",
        "            ReLUActi(),\n",
        "            Vectorizer((64, 7, 7)),\n",
        "            MatrixMult((1, 64 * 7 * 7), (1, 100)),\n",
        "            Addition((1, 100)),\n",
        "            ReLUActi(),\n",
        "            MatrixMult((1, 100), (1, 10)),\n",
        "            Addition((1, 10)),\n",
        "            SoftMaxActi()\n",
        "        ]\n",
        "        self.loss = cross_entropy_loss\n",
        "\n",
        "    def forward(self, input):\n",
        "        output = input\n",
        "        for layer in self.layers:\n",
        "            output = layer.forward(output)\n",
        "        return output[0]\n",
        "\n",
        "    def backward(self, back):\n",
        "        for layer in reversed(self.layers):\n",
        "            back = layer.backward(back)\n",
        "\n",
        "    def update(self, lr):\n",
        "        for layer in self.layers:\n",
        "            layer.update(lr)\n",
        "\n",
        "\n",
        "################ Main ######################################\n",
        "\n",
        "num_train_data = 5000\n",
        "num_test_data = 1000\n",
        "\n",
        "train_data = train_data[:num_train_data]\n",
        "train_labels = train_labels[:num_train_data]\n",
        "test_data = test_data[:num_test_data]\n",
        "test_labels = test_labels[:num_test_data]\n",
        "print(\"Train data\", train_data.shape) \n",
        "print(\"Train labels\", train_labels.shape)\n",
        "print(\"Test data\", test_data.shape)\n",
        "print(\"Test labels\", test_labels.shape)\n",
        "\n",
        "# hyper parameters\n",
        "LEARNING_RATE = 0.01\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "model = Model()\n",
        "\n",
        "t = time()\n",
        "\n",
        "print(\"Training started...\")\n",
        "\n",
        "train_loss_list = []\n",
        "test_acc_list = []\n",
        "\n",
        "# iterate through epochs\n",
        "print('epoch'+'\\t'*2+'time'+'\\t'*2+'CE Loss'+'\\t'*2+'Test Acc')\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    s = time()\n",
        "    lr = LEARNING_RATE\n",
        "    \n",
        "    train_loss = 0\n",
        "    # cycle through the training data\n",
        "    for i in range(len(train_data)):\n",
        "        X = train_data[i]\n",
        "        y = train_labels[i]\n",
        "        pred = model.forward(X)\n",
        "        train_loss += cross_entropy_loss(pred, y)\n",
        "        model.backward(y) # back prop\n",
        "        model.update(lr) # weight update\n",
        "    train_loss_list.append(train_loss)\n",
        "\n",
        "    test_correct = 0\n",
        "    # cycle through the test data\n",
        "    for X, y in zip(test_data, test_labels):\n",
        "        pred = model.forward(X) # forward pass\n",
        "        test_correct += (np.argmax(pred)==y)\n",
        "    test_acc = test_correct/len(test_data) # accuracy\n",
        "    test_acc_list.append(test_acc)\n",
        "\n",
        "    e = time()\n",
        "\n",
        "    # per epoch display (epoch, time, training loss, testing accuracy)\n",
        "    print('\\r'+'{0}'.format(epoch+1)+'\\t'*2+'{0:.2f}s'.format(e-s)+'\\t'*2+'{0:.2f}'.format(train_loss)+'\\t'*2+'{0:.2f}%'.format(test_acc*100))\n",
        "\n",
        "print(\"Training completed.\")\n",
        "\n",
        "time_taken = time() - t\n",
        "\n",
        "test_predicted_labels = []\n",
        "test_loss = 0\n",
        "num_correct = 0\n",
        "for X, y in zip(test_data, test_labels):\n",
        "    pred = model.forward(X) # forward pass\n",
        "    test_predicted_labels.append(np.argmax(pred))\n",
        "    test_loss += cross_entropy_loss(pred, y)\n",
        "    num_correct += (np.argmax(pred)==y)\n",
        "test_acc = num_correct / len(test_data) # accuracy\n",
        "\n",
        "################################################################################\n",
        "#\n",
        "# DISPLAY\n",
        "#\n",
        "################################################################################\n",
        "\n",
        "# accuracy display\n",
        "print('Test Accuracy: {:.2f}%'.format(test_acc*100))\n",
        "# final value\n",
        "print('Test Loss: ', test_loss)\n",
        "\n",
        "# plot of train loss per epoch\n",
        "plt.plot(list(range(0,NUM_EPOCHS)), train_loss_list)\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('Training Cross Entropy Loss')\n",
        "plt.show()\n",
        "\n",
        "# plot of test accuracy vs epoch\n",
        "plt.plot(list(range(0, NUM_EPOCHS)), test_acc_list)\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.show()\n",
        "\n",
        "# performance display\n",
        "# total time\n",
        "print('Training Time Taken: ', time_taken)\n",
        "# per layer info (type, input size, output size, parameter size, MACs, ...)\n",
        "print(\"Layer type\"+'\\t'*2+\"Input size\"+'\\t'*3+\"Output size\")\n",
        "for j in model.layers:\n",
        "    print(type(j).__name__+'\\t'*2+str(j.input_size)+'\\t'*3+str(j.output_size))\n",
        "\n",
        "# example display\n",
        "# replace the xNN predicted label with the label predicted by the network\n",
        "fig = plt.figure(figsize=(DISPLAY_COL_IN, DISPLAY_ROW_IN))\n",
        "ax = []\n",
        "for i in range(DISPLAY_NUM):\n",
        "    img = test_data[i, :, :, :].reshape((DATA_ROWS, DATA_COLS))\n",
        "    ax.append(fig.add_subplot(DISPLAY_ROWS, DISPLAY_COLS, i + 1))\n",
        "    ax[-1].set_title('True: ' + str(test_labels[i]) + ' xNN: ' + str(test_predicted_labels[i]))\n",
        "    plt.imshow(img, cmap='Greys')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train data (5000, 1, 28, 28)\n",
            "Train labels (5000,)\n",
            "Test data (1000, 1, 28, 28)\n",
            "Test labels (1000,)\n",
            "Training started...\n",
            "epoch\t\ttime\t\tCE Loss\t\tTest Acc\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}